# Выполнение в CUDA операций с матрицами.

### Цель работы

Получить опыт построения программ обработки массивов в GPU с
использованием разделяемой памяти (shared_memory).

### Методические указания

В ходе выполнения работы необходимо построить программу, выполняющую
операции с матрицами. Например, умножение двух матриц с копированием исходных
массивов в глобальную память GPU. Умножение матриц в GPU рассмотреть в двух
вариантах: с копированием данных в разделяемую память GPU и без копирования.
Оценить время вычислений в CPU и GPU.

Отчёт должен содержать исходный текст программы и оценки времени вычислений
в CPU и GPU. 

### Литература

1. А. В. Боресков, А. А. Харламов. Основы работы с технологией CUDA.- М.:ДМК
Пресс, 2013 г.
2. Параллельные вычисления на GPU. Архитектура и программная модель CUDA:
Учебное пособие. А. В. Боресков и др. Предисл.: В. А. Садовничий. Издательство
Московского университета, 2012
3. Джейсон Сандерс, Эдвард Кэндрот. Технология CUDA в примерах. Введение в
программирование графических процессоров. ДМК Пресс, 2011 г.

### Контрольные вопросы

* Каким образом размеры блока влияют на время решения задачи в GPU?
* В каких случаях (почему) копирование данных в разделяемую память не приводит к существенному ускорению вычислений?
